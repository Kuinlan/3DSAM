{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 9, 1, 2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.randint(10, (5,))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "L = 2400\n",
    "C = 600\n",
    "D = 256\n",
    "source = torch.randperm(N*L*D).view(N, L, D).float().cuda()\n",
    "t = torch.linspace(\n",
    "    start=0, end=(N-1)*L, \n",
    "    steps=N, dtype=torch.int32\n",
    ")  \n",
    "t = t[:, None, None].repeat(1, L, C)\n",
    "t1 = torch.randint(\n",
    "    low=0, \n",
    "    high=L, \n",
    "    size=(N, L, C)\n",
    ") \n",
    "ind_global = (t1 + t).flatten(0, -1)\n",
    "output = source.flatten(0, 1)[ind_global, :].view(N, L, -1, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded indices:\n",
      " tensor([[[ 0,  1, -1, -1, -1],\n",
      "         [ 0,  1,  2, -1, -1],\n",
      "         [ 0, -1, -1, -1, -1]],\n",
      "\n",
      "        [[ 0,  1, -1, -1, -1],\n",
      "         [ 0,  1,  2, -1, -1],\n",
      "         [ 0, -1, -1, -1, -1]],\n",
      "\n",
      "        [[ 0,  1, -1, -1, -1],\n",
      "         [ 0,  1,  2, -1, -1],\n",
      "         [ 0, -1, -1, -1, -1]],\n",
      "\n",
      "        [[ 0,  1, -1, -1, -1],\n",
      "         [ 0,  1,  2, -1, -1],\n",
      "         [ 0, -1, -1, -1, -1]]])\n",
      "Mask:\n",
      " tensor([[[ True,  True, False, False, False],\n",
      "         [ True,  True,  True, False, False],\n",
      "         [ True, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True, False, False, False],\n",
      "         [ True,  True,  True, False, False],\n",
      "         [ True, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True, False, False, False],\n",
      "         [ True,  True,  True, False, False],\n",
      "         [ True, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True, False, False, False],\n",
      "         [ True,  True,  True, False, False],\n",
      "         [ True, False, False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设我们有以下变量\n",
    "batch_size = 4\n",
    "num_points = 3\n",
    "max_correspondences = 5  # 这是经过检查我们知道的最大对应点数量\n",
    "\n",
    "# 假设的每个点的对应点数量\n",
    "num_correspondences_per_point = torch.tensor([2, 3, 1])\n",
    "\n",
    "# 创建一个批次中所有点对应的数量的扩展张量\n",
    "expanded_correspondences = num_correspondences_per_point[None, :, None].expand(batch_size, -1, max_correspondences)\n",
    "\n",
    "# 创建一个范围张量，范围是0到最大对应点数\n",
    "range_tensor = torch.arange(max_correspondences)[None, None, :].expand_as(expanded_correspondences)\n",
    "\n",
    "# 使用比较操作来创建掩码\n",
    "mask = range_tensor < expanded_correspondences\n",
    "\n",
    "# 使用掩码来填充索引，我们使用masked_fill来放置-1\n",
    "padded_indices = torch.full(expanded_correspondences.shape, -1)  # 填充-1\n",
    "padded_indices[mask] = range_tensor[mask]\n",
    "\n",
    "print(\"Padded indices:\\n\", padded_indices)\n",
    "print(\"Mask:\\n\", mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 11.329454345703125 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from variable_gather import gather_index\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # 创建两个CUDA事件\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    # 初始化要在GPU上执行的张量\n",
    "    x = torch.randn((4, 4800, 4800), device=\"cuda\") > 0.5\n",
    "\n",
    "    # 记录开始时间\n",
    "    start_event.record()\n",
    "\n",
    "    # 执行某个CUDA操作\n",
    "    for i in range(100):\n",
    "        output = gather_index(x, 880)\n",
    "    \n",
    "    # 记录结束时间\n",
    "    end_event.record()\n",
    "\n",
    "    # 等待事件完成\n",
    "    torch.cuda.synchronize()  # 等待所有CUDA核心完成当前所有已提交的命令\n",
    "\n",
    "    # 计算执行时间\n",
    "    elapsed_time_ms = start_event.elapsed_time(end_event) / 100\n",
    "\n",
    "    print(f\"Execution time: {elapsed_time_ms} ms\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((2, 1200, 1200), device=\"cuda\").flatten(0, 1) > 0.5\n",
    "output = torch.zeros((2, 1200, 440), device=x.device).flatten(0, 1)\n",
    "for i in range(2 * 1200):\n",
    "    count = 0;\n",
    "    for j in range(1200):\n",
    "        if (x[i][j] == True):\n",
    "            output[i, count] = j; \n",
    "            count += 1;\n",
    "        if count >= 440:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def test():\n",
    "    # 假定输入x\n",
    "    x = torch.randn((4, 4800, 4800), device=\"cuda\").flatten(0, 1) > 0.5\n",
    "    \n",
    "    # 创建一个索引张量，大小与x相同\n",
    "    indices = torch.arange(4800, device=x.device).expand_as(x)\n",
    "\n",
    "    # 使用x作为掩码，选取True值的索引\n",
    "    true_indices = torch.where(x, indices, torch.tensor(4800, device=x.device))\n",
    "\n",
    "    # 对true_indices进行排序，因为torch.where不能保证顺序，并且需要去除填充的1200值\n",
    "    sorted_indices, _ = torch.sort(true_indices, dim=1)\n",
    "\n",
    "    # 确保每一行最多只有440个有效索引\n",
    "    # 注意：由于先前步骤中填充的是1200，排序后有效索引将排在前面\n",
    "    output = sorted_indices[:, :880]\n",
    "\n",
    "    # 恢复output的形状以匹配原始需求\n",
    "    output = output.reshape(4, 4800, 880)\n",
    "    return output\n",
    "\n",
    "output = test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 117.86421875 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from variable_gather import gather_index\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # 创建两个CUDA事件\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "\n",
    "    # 记录开始时间\n",
    "    start_event.record()\n",
    "\n",
    "    # 执行某个CUDA操作\n",
    "    for i in range(100):\n",
    "        output = test()\n",
    "\n",
    "    # 记录结束时间\n",
    "    end_event.record()\n",
    "\n",
    "    # 等待事件完成\n",
    "    torch.cuda.synchronize()  # 等待所有CUDA核心完成当前所有已提交的命令\n",
    "\n",
    "    # 计算执行时间\n",
    "    elapsed_time_ms = start_event.elapsed_time(end_event) / 100\n",
    "\n",
    "    print(f\"Execution time: {elapsed_time_ms} ms\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.rand((2, 10, 10), device='cuda:0') > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_ids, i_ids, j_ids = torch.where(mask)\n",
    "num_gt_b = torch.sum(mask, dim=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([50, 40], device='cuda:0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_ids, num_gt_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_cumsum = torch.cumsum(num_gt_b, 0)\n",
    "idx_cumsum = num_gt_b.cumsum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-50\n",
      "\n",
      "50-90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bs = idx_cumsum.shape[0]\n",
    "for idx in range(bs):\n",
    "    low = 0 if idx == 0 else idx_cumsum[idx-1]\n",
    "    high = idx_cumsum[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.geometry.epipolar import find_essential, decompose_essential_matrix\n",
    "\n",
    "# padded gt matches [N, PAD_NUM_MIN, 2]\n",
    "index0 = torch.randint(0, 50, (32, ))\n",
    "index1 = torch.zeros((32, ))\n",
    "index = torch.stack([index0, index1], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1964273117.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    b_ids[~drop, :8] = spv_b_ids[]\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "N = 4\n",
    "C = 32\n",
    "spv_b_ids = torch.randperm(100, dtype=torch.int64)\n",
    "pad_index = torch.zeros((4, 32))\n",
    "drop = torch.tensor([True, False, True, True])\n",
    "b_ids = torch.zeros((N, C), device='cuda:0')\n",
    "b_ids[~drop, :8] = spv_b_ids[pad_index[~drop, :8].flatten(0, 1)].view(-1, 8)  # [3, 8] \n",
    "i_ids[~drop, :8] = spv_i_ids[pad_index[~drop, :8].flatten(0, 1)].view(-1, 8)  # [3, 8] \n",
    "l_ids[~drop, :8] = spv_j_ids[pad_index[~drop, :8].flatten(0, 1)].view(-1, 8)  # [3, 8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.linspace(0, 3, 4).unsqueeze(dim=-1).repeat(1, 32)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6, 9, 3, 4],\n",
      "        [1, 7, 8, 0, 2]])\n",
      "tensor([[2, 4, 0, 1, 4, 4, 0, 4, 4, 2],\n",
      "        [0, 3, 3, 3, 3, 4, 4, 4, 2, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9, 4, 5, 6, 4, 4, 5, 4, 4, 9],\n",
       "        [1, 0, 0, 0, 0, 2, 2, 2, 8, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 示例维度\n",
    "N, L = 2, 5  # N: 批次大小, L: 每个批次的点数\n",
    "D = 64\n",
    "feat = torch.randn((4, 1200, 512))\n",
    "index = torch.randint(0, 1200, (4, 1200, 200))\n",
    "print(points)\n",
    "indices = torch.randint(L, (N, 10))  # 随机生成的需要提取的点的索引\n",
    "print(indices)\n",
    "# 使用高级索引提取点\n",
    "selected_points = points[torch.arange(N).unsqueeze(1), indices]\n",
    "selected_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9495/3982700266.py:12: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400400184/work/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  feat_all_out.grad\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "feat_all = torch.ones((4, 5), requires_grad=True)\n",
    "feat_all_out = feat_all * 2\n",
    "skip_sample = torch.tensor([False, True, False, False])\n",
    "feat = feat_all_out[~skip_sample]\n",
    "feat_out = 2 * feat\n",
    "feat_restore = torch.zeros_like(feat_all)\n",
    "feat_restore[~skip_sample] = feat_out\n",
    "feat_restore[skip_sample] = feat_all_out[skip_sample]\n",
    "feat_restore.backward(torch.ones_like(feat_restore))\n",
    "feat_all_out.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkornia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_meshgrid\n\u001b[0;32m----> 3\u001b[0m kkgrid \u001b[38;5;241m=\u001b[39m create_meshgrid(\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m80\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mint64)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from kornia.utils import create_meshgrid\n",
    "\n",
    "kkgrid = create_meshgrid(60, 80, False, 'cuda', torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
